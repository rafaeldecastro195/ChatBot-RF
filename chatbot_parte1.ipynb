{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "rkt5Q-5bwZ0N"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wMl2Ccaiwbn4"
      },
      "outputs": [],
      "source": [
        "# Guardar a API Key do Google em uma variável. IMPORTANTE: necessária para o funcionamento do chatbot. Obter em Google AI Studio (https://aistudio.google.com/app/apikey)\n",
        "api_key_usuario = 'COLE_AQUI_A_SUA_API_KEY'\n",
        "\n",
        "# Configuração da APi Key para o projeto\n",
        "genai.configure(api_key=api_key_usuario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "UGdwlwclwhyN"
      },
      "outputs": [],
      "source": [
        "# Configurações de Resposta\n",
        "generation_config = {\n",
        "\n",
        "      # A IA pode dar mais de uma resposta, ao colocar 1, haverá apenas uma opção de resposta\n",
        "      'candidate_count':1,\n",
        "\n",
        "      # Controla a criatividade. Quanto mais próximo de 1, mais criativo, porém menos previsível. Quanto mais próximo de 0, menos criativo, porém mais previsível\n",
        "      'temperature':0.6,\n",
        "\n",
        "      # Controla o número de palavras consideradas para completar a frase. Quanto maior o número, mais palavras seão consideradas. Valores maiores são mais criativos, porém menos precisos\n",
        "      'top_k':30,\n",
        "\n",
        "      # Controla a probabilidade total das palavras a serem consideradas para completar a frase. Quanto mais próximo de 1, maior a probabilidade e criatividade, enquanto o mais próximo de 0, menor será essas caractrísticas\n",
        "      'top_p':0.8,\n",
        "\n",
        "      # Define o número máximo de tokens gerados por resposta. Serão geradas em torno de 700 palavras\n",
        "      'max_output_tokens':1024\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NZcFi5BRwjF2"
      },
      "outputs": [],
      "source": [
        "# Configurações de Segurança\n",
        "safety_settings = {\n",
        "\n",
        "     # Bloqueio de Abuso\n",
        "     'HARASSMENT': 'HIGH',\n",
        "\n",
        "     # Bloqueio de Ódio\n",
        "     'HATE': 'HIGH',\n",
        "\n",
        "     # Bloqueio de conteúdo Sexual Explícito\n",
        "     'SEXUAL': 'MEDIUM',\n",
        "\n",
        "     # Bloqueio de Comentários Perigosos\n",
        "     'DANGEROUS': 'MEDIUM'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbseB9_Awkp9"
      },
      "outputs": [],
      "source": [
        "# Lista de modelos Gemini\n",
        "for x in genai.list_models():\n",
        "   if 'generateContent' in x.supported_generation_methods:\n",
        "      print(x.name)\n",
        "\n",
        "# Escolha e Inicialização do modelo (o modelo 1.5 flash será usado)\n",
        "modelo_gemini = genai.GenerativeModel(model_name='gemini-1.5-flash', generation_config=generation_config, safety_settings=safety_settings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interação Usuário-Chatbot\n",
        "\n",
        "# Funções:\n",
        "# Função para obter a entrada do usuário (pergunta)\n",
        "def obter_entrada_usuario():\n",
        "  return input(f'\\n Digite a sua pergunta (ou s para sair): \\n\\n')\n",
        "\n",
        "# Função para enviar a pergunta ao modelo\n",
        "def enviar_pergunta(envio, entrada):\n",
        "  return envio.send_message(entrada)\n",
        "\n",
        "# Função para tratar exceções\n",
        "def tratar_erro(excecao):\n",
        "  return excecao"
      ],
      "metadata": {
        "id": "CchrOFfH8Fni"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dBuQnU1wpD3"
      },
      "outputs": [],
      "source": [
        "# Interação Usuário-Chatbot\n",
        "\n",
        "# Sessão de conversa e criação do histórico da conversa\n",
        "conversa = modelo_gemini.start_chat(history=[])\n",
        "\n",
        "# Loop para que a conversa se alongue enquanto o usuário desejar\n",
        "while True:\n",
        "  try:\n",
        "    entrada_usuario = obter_entrada_usuario()\n",
        "\n",
        "    if entrada_usuario.lower() == 's':\n",
        "      print(f'\\n Obrigado por usar o chatbot!')\n",
        "      break\n",
        "\n",
        "    # Envio da pergunta feita pelo usuário para o modelo\n",
        "\n",
        "    resposta_chatbot = enviar_pergunta(conversa, entrada_usuario)\n",
        "\n",
        "    # Exibição da resposta\n",
        "    print(f'\\n Resposta: {resposta_chatbot.text} \\n\\n')\n",
        "\n",
        "  except Exception as e:\n",
        "      # Conversão da exceção para uma string, para que possa ser procurado um texto específico (no caso, algo que viole as políticas de segurança)\n",
        "      erro_str = str(tratar_erro(e))\n",
        "\n",
        "      # 'finish_reason: SAFETY' simboliza que políticas de segurança foram violadas. Dessa forma, se houver um erro, dentro da exceção, que aponte isso, será enviada a notificação própria para o contexto\n",
        "\n",
        "      if 'finish_reason: SAFETY' in erro_str:\n",
        "          mensagem_erro_seguranca = '\\n Sua pergunta viola políticas de segurança. Por favor, evite linguagem discriminatória, prejudicial ou ofensiva, e também conteúdos sensíveis como violência explícita e conteúdo sexual. \\n\\n'\n",
        "          print(mensagem_erro_seguranca)\n",
        "\n",
        "      # Se houver outros tipos de erros, será exibida a seguinte notificação:\n",
        "      else:\n",
        "          mensagem_erro_generico = f'\\n {pular_linha} Desculpe, mas houve um erro. Por favor, faça sua pergunta novamente. {e} \\n\\n'\n",
        "          print(mensagem_erro_generico)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDEymez0ACqC25L3TdYVIQ"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
